{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Importing the required Libraries**"
      ],
      "metadata": {
        "id": "UIhCefSaqYAG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_CU6qDN8kJhk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading the dataset**\n",
        "\n",
        "The dataset was already divided into training and testing set. If this would not have been the case, we would have manually divided the data set as 70 - 80% training set and remaining in the testing set by the code below.\n",
        "> x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state = 1)"
      ],
      "metadata": {
        "id": "86lA21Raqfcg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, Y_train), (X_test, Y_test) = keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYZzEHUHntOw",
        "outputId": "23373810-d79c-4990-dbc7-3793705c27c3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Getting Familar with the Dataset**"
      ],
      "metadata": {
        "id": "j4B7M1mZrrIS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(X_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8BwenQMom-9",
        "outputId": "c9821928-d684-4a4e-e8a5-b9891547d692"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (60000, 28, 28)\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
            "  175  26 166 255 247 127   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
            "  225 172 253 242 195  64   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
            "   93  82  82  56  39   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
            "   25   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
            "  150  27   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
            "  253 187   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
            "  253 249  64   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
            "  253 207   2   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
            "  250 182   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
            "   78   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Y_train shape:\", Y_train.shape)\n",
        "print(Y_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECXpDKSwp2ZQ",
        "outputId": "0d67bae4-9993-4688-a4ad-452fa6467a8e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Y_train shape: (60000,)\n",
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(X_train[4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "lCtXA7XzqBzK",
        "outputId": "60681c1f-106c-4f5a-b7c1-d54978c57c26"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f7adb73d4e0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will have to normalize the values present in the X_train and X_test for better training and results of the model."
      ],
      "metadata": {
        "id": "aVLsVYGosP3D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = tf.keras.utils.normalize(X_train, axis = 1)\n",
        "x_test = tf.keras.utils.normalize(X_test, axis = 1)"
      ],
      "metadata": {
        "id": "HCX5XUOhqGRK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jw66X_2tpPJ",
        "outputId": "2b60fd82-3b67-4049-a99a-c40e288b4233"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.34058377, 0.55344342, 0.51591571, 0.47675838,\n",
              "        0.16790986, 0.06389561, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.90011425, 0.75986285, 0.82416724, 0.80196443,\n",
              "        0.71081842, 0.42774558, 0.31460214, 0.29919608, 0.35451095,\n",
              "        0.35818467, 0.34876618, 0.33626817, 0.34967436, 0.335178  ,\n",
              "        0.37058415, 0.28257531, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.2716561 , 0.34104081, 0.23362221, 0.35993679,\n",
              "        0.45615513, 0.40289729, 0.40358052, 0.33999555, 0.45477668,\n",
              "        0.45948942, 0.44740712, 0.42458103, 0.40442136, 0.42997581,\n",
              "        0.55369632, 0.76077969, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.03017292, 0.10486738, 0.02115528, 0.11996078,\n",
              "        0.1212039 , 0.11801684, 0.10020112, 0.03708667, 0.39950509,\n",
              "        0.55369632, 0.57601891, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.14658067, 0.42828299,\n",
              "        0.45560051, 0.09781453, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.03736313, 0.41148549, 0.43166863,\n",
              "        0.18093226, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.21908381, 0.44857216, 0.40289072,\n",
              "        0.0959159 , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.10392528, 0.4228827 , 0.44857216, 0.10495473,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.23427223, 0.43137432, 0.33024801, 0.00846409,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.01628112, 0.3610963 , 0.42118438, 0.10242986, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.2279357 , 0.44740712, 0.30909499, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.13428445,\n",
              "        0.45406238, 0.42274688, 0.09680447, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.02871073, 0.39569152,\n",
              "        0.45948942, 0.29239993, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.0047667 , 0.30675154, 0.45477668,\n",
              "        0.39617395, 0.06165059, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.06037819, 0.38381719, 0.45477668,\n",
              "        0.13929404, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.05502122, 0.35591353, 0.38381719, 0.20590283,\n",
              "        0.00180901, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.23605877, 0.40358052, 0.38381719, 0.09310389,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.17070836, 0.42952046, 0.40358052, 0.38381719, 0.09310389,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.33861822, 0.450819  , 0.40358052, 0.330929  , 0.07161837,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.33861822, 0.450819  , 0.32890224, 0.02719964, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Building the Model**\n",
        "> We need to keep in mind that we have to flatten the x_train and x_test dataset"
      ],
      "metadata": {
        "id": "v-NWPDq0twKu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Flatten(input_shape = (28,28)))\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "model.add(Dense(32, activation = 'relu'))\n",
        "model.add(Dense(10, activation = 'softmax'))"
      ],
      "metadata": {
        "id": "wN4wHNAhtrkw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xK7OfikuZVS",
        "outputId": "4f8fc209-789e-4e10-f6a5-7336ad173739"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               100480    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 32)                4128      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 104,938\n",
            "Trainable params: 104,938\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    optimizer = tf.keras.optimizers.Adam(0.001))"
      ],
      "metadata": {
        "id": "XQrYIfK0ubcy"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train, Y_train, epochs = 15, validation_split = 0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtR8ZwTOvMPB",
        "outputId": "88fb4f39-2ea9-4637-8ee1-2d3d0c5ba58c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0874 - val_loss: 0.1198\n",
            "Epoch 2/15\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0647 - val_loss: 0.1083\n",
            "Epoch 3/15\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0481 - val_loss: 0.1086\n",
            "Epoch 4/15\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0377 - val_loss: 0.0985\n",
            "Epoch 5/15\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0289 - val_loss: 0.1024\n",
            "Epoch 6/15\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0229 - val_loss: 0.1109\n",
            "Epoch 7/15\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0179 - val_loss: 0.1284\n",
            "Epoch 8/15\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0153 - val_loss: 0.1154\n",
            "Epoch 9/15\n",
            "1500/1500 [==============================] - 7s 4ms/step - loss: 0.0127 - val_loss: 0.1260\n",
            "Epoch 10/15\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0120 - val_loss: 0.1203\n",
            "Epoch 11/15\n",
            "1500/1500 [==============================] - 7s 4ms/step - loss: 0.0100 - val_loss: 0.1295\n",
            "Epoch 12/15\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0068 - val_loss: 0.1264\n",
            "Epoch 13/15\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0096 - val_loss: 0.1479\n",
            "Epoch 14/15\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0083 - val_loss: 0.1525\n",
            "Epoch 15/15\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0066 - val_loss: 0.1474\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7ab857a890>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_prob = model.predict(x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPyhdn3UvaPp",
        "outputId": "5d42f401-d3b4-402f-9ad2-2ca6c9b0f2b1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_prob"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpL5yjixw5Od",
        "outputId": "af0099f9-8462-4040-ae99-0f4642cec0af"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.5879612e-15, 6.4601308e-16, 1.0267208e-13, ..., 9.9999994e-01,\n",
              "        7.9948621e-17, 1.0432399e-12],\n",
              "       [6.2927320e-19, 5.7345031e-09, 9.9999994e-01, ..., 2.0424075e-17,\n",
              "        1.9069716e-13, 3.3946640e-25],\n",
              "       [7.5389289e-10, 9.9997789e-01, 2.0033627e-07, ..., 2.1865333e-05,\n",
              "        1.5545551e-08, 1.5420283e-11],\n",
              "       ...,\n",
              "       [8.2201977e-22, 1.0297267e-14, 9.9072719e-17, ..., 1.9850123e-11,\n",
              "        2.8569307e-14, 3.3866576e-10],\n",
              "       [9.3099855e-13, 4.3107835e-13, 4.5889488e-15, ..., 3.5090163e-13,\n",
              "        6.5378130e-09, 1.3495789e-16],\n",
              "       [7.1757621e-11, 1.4821765e-17, 2.6360762e-15, ..., 8.5558371e-23,\n",
              "        7.7658167e-16, 2.1558209e-18]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = y_prob.argmax(axis = 1)"
      ],
      "metadata": {
        "id": "2-fe-A3qw8oB"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(Y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69JV9EAExPsh",
        "outputId": "63463c68-6d4c-47f4-8492-944b3a8a5279"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9739"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ft_R2hna0RE-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}